# Постановка задачи

Цель состояит в том, чтобы по некому заданному N измерений характеристик сигнала от некого статичного источника сигнала, определить его местоположение. По сути задача локализации источника сигнала. Измерение собой представляет точку в пространсвте, в который была измерена сила сигнала RSSI на заданной частоте Freq, а также некоторые другие характеристики. На данном этапе разработки целью является создание прототипа модели машинного обучения, способного решить данную задачу с точностью хотя бы выше нуля. Для упрощения модели опустим все физические характеристики сигнала кроме RSSI, поскольку он является основополагающим знанием. 

**Цель:** Локализация источника сигнала по измерениям силы принимаемого сигнала (RSSI).  
**Задача модели:** Для каждой точки измерения предсказать направление и угол обзора (FoV), где вероятно находится источник.

**Сценарий использования:**
1. **Первое измерение:** Модель предсказывает угол обзора 360° (направление не определено).
2. **Второе измерение:** Уточнение угла обзора (<360°) и появление примерного направления.
3. **Последующие измерения:** Постепенное уменьшение угла обзора и уточнение направления.

# Формат данных

Датасет хранится в файле dataset.csv следующей структуры:

        source_id,longitude,latitude,rssi,source_longitude,source_latitude
        0,1185,567,-128.67,638,587
        0,1208,638,-130.44,638,587
        ...
        752,223,624,-115.12,507,608
        752,172,646,-118.5,507,608

Для большей наглядности представим его в виде:

    source_id { 
  
      features:
        [x_1, x_2, ..., x_n],  - координата точки измерения (широта)
        [y_1, y_2, ..., y_n],  - координата точки измерения (долгота)
        [rssi_1, rssi_2, ..., rssi_n] - сила сигнала в точке измерения
    
      targets:
        source_x,  - координата источника (широта)
        source_y,  - координата источника (долгота)=
    }

source_id представляет собой 1 тренеровочную запись. То есть имея на входе N измерений, мы для них должны получить координату источника. 

Модель должна научиться учитывать:
- Пространственную составляющую: как точки измерений расположены друг относительно друга, на каком расстоянии и с какой стороны
- Физическую (?) составляющую: меньшая rssi должна вносить меньший вклад в предсказание


# Предобработка данных

### Координаты

Все координаты первым делом должны пройти минмакс масштабирование в промежуток от 0 до 1, причем мин и макс координаты нужно задать заранее, чтобы определить рабочу область:

$$
x_{\text{norm}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}}, \quad
y_{\text{norm}} = \frac{y - y_{\min}}{y_{\max} - y_{\min}}
$$

Даже не смотря на нормализацию, значения координат являются скорее категориальным признаком, меткой, уникальное количество которых зависит от точности числа. Проще говоря - для модели эти числа ничего не значат. В кажестве аналогии можно привести языковые модели - там для первичного кодирования каждого слова используется его индекс в алфавите, мощность которого тоже может быть достаточно большой. Для решения этой проблемы используют распределенные векторные представления (известные также как эмбеддинги), которые охватывают понятие сходства и семантического значения, позволяя сущности быть представленной шаблоном значений во многих измерениях. Word2Vec является наглядным примером такого преобразования. Для создания эмбеддинга координат можно воспользоваться такими методами как [Признаки Фурье для кодирования координат](https://sair.synerise.com/fourier-feature-encoding/) или [Пространсвтенное кодирование](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1), которое применяется в трансформерах, и основано на признаках Фурье:

$$
\mathrm{PE}(x, i) = \sin\\bigl(x \cdot 10000^{-\tfrac{2i}{d}}\bigr), \quad
\mathrm{PE}(x, i+1) = \cos\\bigl(x \cdot 10000^{-\tfrac{2i}{d}}\bigr)
$$

где d — размерность эмбеддинга, i — индекс измерения.

Допустим если взять min = 0 и max = 10, и закодировать в этих пределах координату {5;7}, сначала она станет {0.5;0.7}, а потом 
          
    tensor[ 0.4794,  0.8776, -0.2624,  0.9650,  0.6442,  0.7648,  0.7739,  0.6333]

при размерности тензора = 8. Можно брать и больше, это по сути гиперпараметр.


### Сила сигнала (RSSI)

Данный параметр пока что единственное что характеризует расстояние до источника сигнала:

$$
P_d = P_0 - 10 \cdot n \cdot \lg\\bigl(\tfrac{d}{d_0}\bigr)
$$

Видно что по отношению к расстоянию данный параметр имеет логарифмическую зависимость. Можно было бы от нее избавиться во время нормализации, но я думаю что данную специфику лучше учесть при построении функции потерь либо физически информированного модуля сети. 
Так или иначе данный параметр необходимо нормализоватть в промежуток от 0 до 1. мин и макс параметры для RSSI будут -30 (отличный сигнал) и -120 (сигнал потерян). Эти границы могут разнитсья в зависимости от стандарта связи, но суть остается та же.

### FoV

// TODO



По итогу получается датасет следующей структуры:

    | Features:
    | ├─ RSSI: (BATCH_SIZE, MEASUREMENT_COUNT, 1)
    | └─ Coordinates: (BATCH_SIZE, MEASUREMENT_COUNT, d)
    |
    | Targets:
    | └─ Source Coords: (BATCH_SIZE, 1, d)


Где BACTH_SIZE - размер выборки (количество source_id), MEASUREMENT_COUNT - количество точек измерений, d - размерность эмбеддинга для пространственного кодирования


# Цели обучения

Конечной и главной целью модели является предсказание точной координаты источника сигнала. Однако эту цель можно разбить на несколько подцелей:
1) Предсказания направления к источнику сигнала из каждой точки измерения. Пространственная характеристика, которая в большей степени зависит от от геометрии задачи, и в меньшей от RSSI (хватит простого в А больше чем в В)  
2) Предсказание расстояния от каждой точки измерения до источника сигнала. Данный параметр непосредственно связан с RSSI, который логарифмически зависит от расстояния до источника. На деле также зависит от среды распространения, но это скорее физическая поправка.
3) Усреднение направления и расстояния от всех точек измерения и нахождение координаты или области расположения источника.

**Отсюда могу построить предположение: На этапе предобучения модель должна с нуля научиться с какой-то точностью предсказывать шаги 1 и 2. Затем веса модели будут уточняться, вноситься поправки на физику распространения сигнала, и модель будет дообучаться до шага 3.**


# Выбор модели

Пока стоит состредоточиться на выборе модели для этапа предобучения. Решаемая задача по сути своей представляет обыкновенную регрессию, но так как данные имею пространственный характер, то на ум приходят CNN и GNN

### Сравнение CNN и GNN для предобучения (шаги 1 и 2)

| **Критерий**               | **CNN**                          | **GNN**                          |
|----------------------------|----------------------------------|-----------------------------------|
| **Обработка геометрии**     | (-) Требует преобразования данных в регулярную сетку (искажает произвольное расположение точек). | (+) Работает с исходными координатами, сохраняя пространственные отношения через граф. |
| **Учет физических законов** | (-) Зависит от ручных признаков (например, RSSI как функция расстояния). | (+) Явное моделирование через признаки ребер (расстояние, RSSI). |
| **Предсказание азимутов**   | (?) Локальные паттерны (только при регулярных точках). | (+) Точно вычисляет углы через геометрию графа. |
| **Предсказание расстояний** | (-) Сложность учета нелинейной зависимости RSSI. | (+) Интеграция формулы затухания сигнала через агрегацию в GNN. |
| **Масштабируемость**       | (?) Ограничено размером "изображения". | (+) Поддерживает переменное число точек. |

Помимо этого GNN будет занимать гораздо меньше памяти, поскольку ей нужно хранить лишь информацию о точках измерений и связях, а не весь фрагмент карты (сетку)



# Архитектура модели
**Тип архитектуры:** Графовая нейронная сеть (GNN) с механизмом внимания (GAT).  

**Структура:**
| Слой                 | Размерность | Активация      |
|-----------------------|-------------|----------------|
| Входной слой          | `1 + 2d`    | -              |
| GAT 1                 | 512         | Leaky ReLU     |
| GAT 2                 | 512         | Leaky ReLU     |
| GAT 3                 | 512         | Leaky ReLU     |
| GAT 4                 | 512         | Leaky ReLU     |
| Линейный слой         | 256         | -              |
| Выходной слой         | 3           | `tanh` (первые 2 нейрона), `softmax` (последний нейрон) |

**Выход модели:**  
- 2 нейрона с `tanh`: кодируют направление (sinθ, cosθ).  
- 1 нейрон с `softmax`: ширина FoV в радианах (положительное значение).

---

## 3. Функция потерь
Гибридная функция, включающая три компонента:
1. **Ошибка попадания:** Штраф за непопадание истинного источника в предсказанный FoV.
2. **Ошибка направления:** Штраф, обратно пропорциональный разнице между истинным и предсказанным направлением.
3. **Ошибка ширины:** Штраф за несоответствие ширины FoV количеству вершин (слишком узкий при малом числе измерений, слишком широкий при большом).

---

## 4. Метрики оценки
### Таблица метрик для оценки одного предсказания (1 семпл, набор измерений)
| Название метрики                                                                 | Описание                                                                 | Интерпретация                                                                 |
|-----------------------------------------------------------------------------------|-------------------------------------------------------------------------|--------------------------------------------------------------------------------|
| **hits_percent**<br>(HP)                                      | Доля попаданий истинного источника в FoV                                | процент "приблизительно верных" FoV в сессии. Чем больше тем лучше          |
| **accuracy_hits_percent**<br>(AcHP)                            | Доля хитов с шириной FoV ≤ заданной точности                            | процент "метких" FoV в сессии. Чем больше тем лучше                                  |
| **mean_abs_direction_difference**<br>(MADD)                | Средняя абсолютная разница между истинным и предсказанным направлением. | Среднее отклонение направления FoV. Чем меньше тем лучше                                         |
| **mean_abs_width**<br>(MAW)                                   | Средняя ширина FoV                              | Сама по себе ничего не значит, используетсмя для других метрик |
| **adjusted_FoV_score**<br>(AFS)                               | Ожидаемый FoV = 360° / (1 + 0.5 * n^{0.7}), n - количество точек; AFS = MAW / Ожидаемый FoV | Показывает как изменяется FoV в зависимости от количества вершин. < 1: FoV уже ожидаемого (хороший результат для текущего количества точек). ≈ 1: FoV близок к ожидаемому. > 1: FoV шире ожидаемого (плохой результат). Чем меньше AFS, тем лучше модель адаптирует FoV к количеству данных. Если AFS растет с увеличением `n` → модель не сужает FoV при добавлении точек. Если AFS < 1 для всех `n` → модель слишком "консервативна" (даже при малых данных дает узкий FoV).    |


### Таблица метрик для оценки группы предсказаний на выборке


| Название метрики                                                                 | Описание                                                                 | Интерпретация                                                                 |
|-----------------------------------------------------------------------------------|-------------------------------------------------------------------------|--------------------------------------------------------------------------------|
| **mean_<METRICT>**<br>(Avg_<METRIC>)                                      | Среднее значение метрики по всей выборке                                | Аналогично METRIC          |
| **median_<METRICT>**<br>(Med_<METRIC>)                                      | Медианное значение метрики по всей выборке                                | Аналогично METRIC          |
| **mean_abs_width_by_<sample_size_range>**<br>(Avg_AW_<A_B>)                | Средняя ширина FoV для диапазона измерений                              | Зависимость ширины FoV от количества данных. Хорошо когда чем меньше вершин тем больше ширина|
| **median_abs_width_by_<sample_size_range>**<br>(Med_AW_<A_B>)            | Медианная ширина FoV для диапазона измерений                            | Зависимость ширины FoV от количества данных. Хорошо когда чем меньше вершин тем больше ширина|

**Примечания:**
- <METRIC> это каждая метрика из таблицы для семпла
- Формат для диапазонов: `<sample_size_range>` заменяется на `A_B` (например, `mean_width_by_0_10` → MEAN_W_0_10).
- **"Хит (Hit)"** - факт попадания истиной координаты в предсказанный FoV.
- **"Приблизительно верное предсказание"** - хит с любой шириной FoV.
- **"Меткое предсказание"** — хит, где ширина FoV не превышает заданный порог точности.
- Ожидаемый FoV = 360° / (1 + 0.5 * n^{0.7}) подобрано эмпирически, для n = 2 ожидаемый FoV = 198.6 deg, а для n = 100 FoV = 26.5 deg
